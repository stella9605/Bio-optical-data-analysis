#### train,test data set
run profile_project

train = pd.read_csv('train.csv', index_col=0)
test = pd.read_csv('test.csv', index_col=0)


################################################################ new 결측지 보완
# 결측치 보완
train_src = train.filter(regex='_src$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_src = test.filter(regex='_src$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
test_dst.head(1)

# na컬럼 인덱스
train_index_na=train_src.isna().values | train_dst.isna().values
test_index_na=test_src.isna().values | test_dst.isna().values

# 보간(형식적)
train_dst = train_dst.interpolate(methods='quadratic', axis=1)
test_dst = test_dst.interpolate(methods='quadratic', axis=1)
train_src = train_src.interpolate(methods='quadratic', axis=1)
test_src = test_src.interpolate(methods='quadratic', axis=1)
# 스팩트럼 데이터에서 보간이 되지 않은 값은 'bfill'로 일괄 처리한다.
train_dst=train_dst.apply(lambda x : x.fillna(method='bfill') ,axis=1) 
test_dst=test_dst.apply(lambda x : x.fillna(method='bfill') ,axis=1) 
train_src=train_src.apply(lambda x : x.fillna(method='bfill') ,axis=1) 
test_src=test_src.apply(lambda x : x.fillna(method='bfill') ,axis=1) 

train.update(train_dst) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_dst)
train.update(train_src) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_src)

X = train.iloc[:, :-4]
Y = train.iloc[:,-4:]

Y_1 = Y.iloc[:,0:1]
Y_2 = Y.iloc[:,1:2]
Y_3 = Y.iloc[:,2:3]
Y_4 = Y.iloc[:,3:4]

# train 변수 튜닝
tunning_X = X.apply(tuning_var, axis = 1)
tunning_test = test.apply(tuning_var, axis = 1)

# 이제 반사도 컬럼으로 변환됐으니 na값을 가졌던 컬럼인덱스를 사용해 NaN을 넣어준다 
tunning_X.iloc[:,1:].values[train_index_na]=np.NaN
tunning_test.iloc[:,1:].values[test_index_na]=np.NaN

# 최종 보간
tunning_X = tunning_X.interpolate(methods='quadratic', axis=1)
tunning_test = tunning_test.interpolate(methods='quadratic', axis=1)
# 스팩트럼 데이터에서 보간이 되지 않은 값은 'bfill'로 일괄 처리한다.
tunning_X=tunning_X.apply(lambda x : x.fillna(method='bfill') ,axis=1) 
tunning_test=tunning_test.apply(lambda x : x.fillna(method='bfill') ,axis=1) 

# train, test set
#### hhb
train_x_hhb, test_x_hhb, train_y_hhb, test_y_hhb = train_test_split(tunning_X,
                                                                    Y_1,
                                                                    random_state = 0)

#### hbo2
train_x_hbo2, test_x_hbo2, train_y_hbo2, test_y_hbo2 = train_test_split(tunning_X,
                                                                        Y_2,
                                                                        random_state = 0)
 
#### ca
train_x_ca, test_x_ca, train_y_ca, test_y_ca = train_test_split(tunning_X,
                                                                Y_3,
                                                                random_state = 0)

#### na
train_x_na, test_x_na, train_y_na, test_y_na = train_test_split(tunning_X,
                                                                Y_4,
                                                                random_state = 0)

## new 결측치 보완은 튜닝 전,후를 다 보완했기 때문에 이미 튜닝이 되있는 상태입니다.


############################################## 모델 변경(RandomForestRegressor)

## hhb
m_rf_hhb = rf_r()
m_rf_hhb.fit(train_x_hhb, list(train_y_hhb.iloc[:,0]))

test_y_hhb_predict = m_rf_hhb.predict(test_x_hhb)
train_y_hhb_predict = m_rf_hhb.predict(train_x_hhb)

####MAE
mean_absolute_error(train_y_hhb, train_y_hhb_predict)       # 0.29
mean_absolute_error(test_y_hhb, test_y_hhb_predict)         # 0.77

## hbo2 
m_rf_hbo2 = rf_r()
m_rf_hbo2.fit(train_x_hbo2, list(train_y_hbo2.iloc[:,0]))

test_y_hbo2_predict = m_rf_hbo2.predict(test_x_hbo2)
train_y_hbo2_predict = m_rf_hbo2.predict(train_x_hbo2)

####MAE
mean_absolute_error(train_y_hbo2, train_y_hbo2_predict)       # 0.21
mean_absolute_error(test_y_hbo2, test_y_hbo2_predict)         # 0.57

## ca
m_rf_ca = rf_r()
m_rf_ca.fit(train_x_ca, list(train_y_ca.iloc[:,0]))

test_y_ca_predict = m_rf_ca.predict(test_x_ca)
train_y_ca_predict = m_rf_ca.predict(train_x_ca)

####MAE
mean_absolute_error(train_y_ca, train_y_ca_predict)    # 0.70
mean_absolute_error(test_y_ca, test_y_ca_predict)      # 1.85

## na
m_rf_na = rf_r()
m_rf_na.fit(train_x_na, list(train_y_na.iloc[:,0]))

test_y_na_predict = m_rf_na.predict(test_x_na)
train_y_na_predict = m_rf_na.predict(train_x_na)

####MAE
mean_absolute_error(train_y_na, train_y_na_predict)    # 0.45
mean_absolute_error(test_y_na, test_y_na_predict)      # 1.24


#################################################################### 결측치 보완(ann모델 사용)
train.isnull().sum()[train.isnull().sum().values > 0]
# 결측치 보완
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
test_dst.head(1)

train_dst = train_dst.interpolate(methods='quadratic', axis=1)
test_dst = test_dst.interpolate(methods='quadratic', axis=1)

# 스팩트럼 데이터에서 보간이 되지 않은 값은 0으로 일괄 처리한다.
train_dst.fillna(0, inplace=True) 
test_dst.fillna(0, inplace=True)

test_dst.head(1)

train.update(train_dst) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_dst)

#######################################################################모델 ANN

X = train.iloc[:, :-4]
Y = train.iloc[:,-4:]

# train, test set
#### hhb
train_x_hhb, test_x_hhb, train_y_hhb, test_y_hhb = train_test_split(X,
                                                                    Y_1,
                                                                    random_state = 0)

#### hbo2
train_x_hbo2, test_x_hbo2, train_y_hbo2, test_y_hbo2 = train_test_split(X,
                                                                        Y_2,
                                                                        random_state = 0)
 
#### ca
train_x_ca, test_x_ca, train_y_ca, test_y_ca = train_test_split(X,
                                                                Y_3,
                                                                random_state = 0)

#### na
train_x_na, test_x_na, train_y_na, test_y_na = train_test_split(X,
                                                                Y_4,
                                                                random_state = 0)



# hhb - train,test 변수 튜닝
tunning_train_x_hhb = train_x_hhb.apply(tuning_var, axis = 1)
tunning_test_x_hhb = test_x_hhb.apply(tuning_var, axis = 1)

# hbo2 - train,test 변수 튜닝
tunning_train_x_hbo2 = train_x_hbo2.apply(tuning_var, axis = 1)
tunning_test_x_hbo2 = test_x_hbo2.apply(tuning_var, axis = 1)

# ca - train,test 변수 튜닝
tunning_train_x_ca = train_x_ca.apply(tuning_var, axis = 1)
tunning_test_x_ca = test_x_ca.apply(tuning_var, axis = 1)

# na - train,test 변수 튜닝
tunning_train_x_na = train_x_na.apply(tuning_var, axis = 1)
tunning_test_x_na = test_x_na.apply(tuning_var, axis = 1)


# hhb - 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x_hhb)

x_scaled_hhb = m_sacled.transform(tunning_train_x_hhb)
test_x_scaled_hhb = m_sacled.transform(tunning_test_x_hhb)

# hbo2 - 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x_hbo2)

x_scaled_hbo2 = m_sacled.transform(tunning_train_x_hbo2)
test_x_scaled_hbo2 = m_sacled.transform(tunning_test_x_hbo2)

# ca - 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x_ca) 

x_scaled_ca = m_sacled.transform(tunning_train_x_ca)
test_x_scaled_ca = m_sacled.transform(tunning_test_x_ca)

# na - 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x_na)

x_scaled_na = m_sacled.transform(tunning_train_x_na)
test_x_scaled_na = m_sacled.transform(tunning_test_x_na)


# 모델 생성 함수 사용해서 모델생성
model_hhb = model_x(x_scaled_hhb, train_y_hhb, 500)
model_hbo2 = model_x(x_scaled_hbo2, train_y_hbo2, 500)
model_ca = model_x_test(x_scaled_ca, train_y_ca, 500)
model_na = model_x_test(x_scaled_na, train_y_na, 500)


# 모델 test
#### hhb
print("\n MAE: %.4f" % (model_hhb.evaluate(x_scaled_hhb,train_y_hhb)[1]))           # 0.83
print("\n MAE: %.4f" % (model_hhb.evaluate(test_x_scaled_hhb,test_y_hhb)[1]))       # 0.96

#### hbo2
print("\n MAE: %.4f" % (model_hbo2.evaluate(x_scaled_hbo2,train_y_hbo2)[1]))          # 0.57
print("\n MAE: %.4f" % (model_hbo2.evaluate(test_x_scaled_hbo2,test_y_hbo2)[1]))      # 0.66

#### ca
print("\n MAE: %.4f" % (model_ca.evaluate(x_scaled_ca,train_y_ca)[1]))          # 1.7   
print("\n MAE: %.4f" % (model_ca.evaluate(test_x_scaled_ca,test_y_ca)[1]))      # 2.0

#### na
print("\n MAE: %.4f" % (model_na.evaluate(x_scaled_na,train_y_na)[1]))          # 1.1
print("\n MAE: %.4f" % (model_na.evaluate(test_x_scaled_na,test_y_na)[1]))       # 1.2


############################################################# TEST.csv 채워넣기

from keras.models import load_model
model_hhb.save('model_hhb_ann_bio_h5')   # h5 확장자로 저장 (hhb)
model_hbo2.save('model_hbo2_ann_bio_h5')   # hbo2
model_ca.save('model_ca_ann_bio_h5')   # ca
model_na.save('model_na_ann_bio_h5')   # na

dir(model)
model2_hhb=load_model('model_hhb_ann_bio_h5')
model2_hbo2=load_model('model_hbo2_ann_bio_h5')
model2_ca=load_model('model_ca_ann_bio_h5')  
model2_na=load_model('model_na_ann_bio_h5') 

## sample_submission.csv load
test1=pd.read_csv('sample_submission.csv',index_col='id')
test1=test1.astype('float')

# 진짜 테스트 변수 가공
tunning_realtest_x = test.apply(tuning_var_test, axis = 1)
realtest_x_scaled = m_sacled.transform(tunning_realtest_x)

########## ann 모델
test1.hhb=model2_hhb.predict(realtest_x_scaled)
test1.hbo2=model2_hbo2.predict(realtest_x_scaled)
test1.ca=model2_ca.predict(realtest_x_scaled)
test1.na=model2_na.predict(realtest_x_scaled)
test1.to_csv("test 2020-6-17.csv")


########## RandomForestRegressor 모델
test1.hhb=m_rf_hhb.predict(realtest_x_scaled)
test1.hbo2=m_rf_hbo2.predict(realtest_x_scaled)
test1.ca=m_rf_ca.predict(realtest_x_scaled)
test1.na=m_rf_na.predict(realtest_x_scaled)
test1.to_csv("test 2020-6-17.csv")
