### 오늘 한 거 정리(Yoo)
- 지금껏 4가지의 y값을 예측하는 1개의 모델을 돌렸는데, 이렇게 한번에 예측할 때 모델에서 중간에 꺼지는 노드에 대해 모든 Y값이 영향을 받는 것이기 때문에 어떤 Y값에 대해서는 그런 영향이 부정적이라면 이 모델은 예측력이 낮을 것입니다. 따라서 각 Y에 대한 모델을 하나씩 만들어서 나중에 병합하는 방향으로 설정했습니다. 
- 그리고 4가지 물질이 각 파장(설명변수)에 대해서 흡수하는 정도가 다르기 떄문에 각 물질이 존재하는 정도(농도)가 서로한테 영향을 분명히 줄거라고 생각해서 각 모델에서 제외될 Y값들을 설명변수로서 추가하도록 했습니다. 

#### 1번 내용은 아직 4개의 모델로 나누기 전까지 모든 Y값을 종속변수로 넣은 모델입니다.
(감쇠계수를 고려해서 짠 찬희씨 모델에 적용하겠습니다 . chan profile No1에서 확인가능)
- 참고로 다시 정리하자면 모델은 train.csv에 있는 데이터를 train과 test로 나눠 모델링해 평가까지 진행하고, test.csv에 있는 값을 모델에 최종적으로 적용해 y값을 예측합니다. 

##### 1번)
```python
run profile1
import math
train = pd.read_csv('train.csv', index_col=0)
test = pd.read_csv('test.csv', index_col=0)

train.head()

train.isnull().sum()[train.isnull().sum().values > 0]

# 결측치 보완
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
test_dst.head(1)

train_dst = train_dst.interpolate(methods='quadratic', axis=1)
test_dst = test_dst.interpolate(methods='quadratic', axis=1)

# 스팩트럼 데이터에서 보간이 되지 않은 값은 0으로 일괄 처리한다.
train_dst.fillna(0, inplace=True) 
test_dst.fillna(0, inplace=True)

test_dst.head(1)

train.update(train_dst) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_dst)

X = train.iloc[:, :-4]
Y = train.iloc[:,-4:]

train_x, test_x, train_y, test_y = train_test_split(X,
                                                    Y,
                                                    random_state = 0)


# 각 조직에 관환 감쇠계수
attenuation_coefficient = pd.DataFrame({'NIR-1' : [10,48,25], 'NIR-2' : [7.4,45,23],'SWIR' : [6.5,44,21],'SWIR-2' : [9,49,24.5]})
attenuation_coefficient.index = ['Brain_cortex','Cranial_bone','Skin']
attenuation_coefficient.sum(axis = 0)

n =  attenuation_coefficient.sum(axis = 0)['NIR-2'] # 감쇠계수

## 튜닝 함수
def tuning_var(s):
    s_rho = s[0]          # _rho
    s_src = s[1:36]       # _src
    s_dst = s[36:]        # _dst    

    # index 표준화
    set_index = s_src.index.str.split('_').str[0]
    s_src.index = set_index
    s_dst.index = set_index

    # 계산식 (lambert beer 법칙)
    # A(흡광도) = -log10(I(투과방사선)/I0(입사방사선))  
    #           = ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도)
    
    # 투광도
    transmittance = (s_dst / s_src)
    
    # 계산 완료후 inf,nan 0으로 치환
    transmittance = [i if i != np.inf else 0.0 for i in transmittance ]
    transmittance = Series(transmittance).fillna(value = 0)

    # math.log 계산을 위해 0을 1로 치환후 계산(흡광계수는 1로 가정한다.)
    transmittance = Series([1 if i == 0 else i for i in transmittance ])
    
    #흡광도_1 : -log10(I(투과방사선)/I0(입사방사선))  
    absorbance_1 = Series(map(lambda x : -math.log(x,10),transmittance))
    
    #흡광도_2 :  ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도) (농도는 1로 가정)
    # 흡광계수는 3번째 논문에서 찾은 적외선 종류중 NIR-1 의 뇌피질, 두개골, 피부의 감쇠계수의 합을 적용시켰습니다.
    absorbance_2 = Series(1/(((((s_rho)/10)**2)*2) * (n * 2.01)))
    
    # 흡광도 index 설정
    absorbance_1.index = set_index.map(lambda x : 'A1_' + x)
    absorbance_2.index = ['A2_rho']
    
    # 두 Series의 병합
    out_s = Series()
    out_s = out_s.append(absorbance_2).append(absorbance_1)
    # 튜닝된 설명변수의 Series반환
    return(out_s)

# train 변수 튜닝
tunning_train_x = train_x.apply(tuning_var, axis = 1)
tunning_test_x = test_x.apply(tuning_var, axis = 1)

# 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x)

x_scaled = m_sacled.transform(tunning_train_x)
test_x_scaled = m_sacled.transform(tunning_test_x)

# 모델의 설정
model = Sequential() 
model.add(Dense(18, input_dim=36, activation='relu')) 
model.add(Dense(8, activation='relu'))
model.add(Dense(4, activation='relu'))
 
# 모델 컴파일  
model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['MAE']) 
 
# 모델 실행 
model.fit(x_scaled, train_y, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(x_scaled,train_y)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x_scaled,test_y)[1]))

# 평가
tunning_realtest_x = test.apply(tuning_var, axis = 1)  # 실제 test의 X값 개수를 흡광도 식을 통해 축소
realtest_x_scaled = m_sacled.transform(tunning_realtest_x) # 스케일링

model611=load_model('model_ann_bio_611_h5')
model611.evaluate(test_x_scaled,test_y)[1] # 1.32, 인위적으로 나눈 test에 대한 평가
virtual_test_Y=model611.predict(realtest_x_scaled) # 실제 test.csv에 있는 값 적용해 y값 얻기
```  
- 마지막에 보면 최종적으로 test.csv에 있는 값을 모델에 적용하면 Y에 대한 예측값이 나옵니다. 이것을 virtualtest라고 부르겠습니다. 
- 이 Y값이 필요한 이유는 설명변수로서 Y값이 필요하기 때문이고 그 Y값을 다시 설명변수로 적용하려는 겁니다. 즉, 예측의 예측...ㅠㅠ
-------------------------------------------------------------------------------
--------------------------------------------------------------------------------
- 이제 모델을 4개의 y값을 각각 한개의 종속변수로 설정하는 모델 4개를 만들건데, X*(X에서 축소된 흡광도컬럼)와 Y값들은 서로 다른 단위를 가지는 수치로 표현되어있어서 같이 스케일링을 적용하면 Y값이 상대적으로 크게되서 역효과가 날 것 같아 각각 스케일링을 했습니다. 즉, 2번 스케일링 
```python
# Y, virtual_test_Y 스케일링 및 x만 있는 test.csv에 예측한 virtual_test_Y 결합하기  
m_sacled = StandardScaler()

m_sacled.fit(Y) # Y는 1번 코드에서 보면 알겠지만 train의 Y입니다.
Y_scaled = m_sacled.transform(Y)
train.iloc[:,-4:]=Y_scaled 

m_sacled.fit(virtual_test_Y)
realtest_Y_scaled = m_sacled.transform(virtual_test_Y)
test=DataFrame(np.append(test,realtest_Y_scaled,axis=1),index=test.index,columns=train.columns)

- virtual_test_Y에 대해서도 같은 스케일링을 적용함



# 각 조직에 관환 감쇠계수
attenuation_coefficient = pd.DataFrame({'NIR-1' : [10,48,25], 'NIR-2' : [7.4,45,23],'SWIR' : [6.5,44,21],'SWIR-2' : [9,49,24.5]})
attenuation_coefficient.index = ['Brain_cortex','Cranial_bone','Skin']
attenuation_coefficient.sum(axis = 0)

n =  attenuation_coefficient.sum(axis = 0)['NIR-2'] # 감쇠계수

## 튜닝 함수
def tuning_var2(s):
    s_rho = s[0]          # _rho
    s_src = s[1:36]       # _src
    s_dst = s[36:-4]        # _dst    

    # index 표준화
    set_index = s_src.index.str.split('_').str[0]
    s_src.index = set_index
    s_dst.index = set_index

    # 계산식 (lambert beer 법칙)
    # A(흡광도) = -log10(I(투과방사선)/I0(입사방사선))  
    #           = ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도)
    
    # 투광도
    transmittance = (s_dst / s_src)
    
    # 계산 완료후 inf,nan 0으로 치환
    transmittance = [i if i != np.inf else 0.0 for i in transmittance ]
    transmittance = Series(transmittance).fillna(value = 0)

    # math.log 계산을 위해 0을 1로 치환후 계산(흡광계수는 1로 가정한다.)
    transmittance = Series([1 if i == 0 else i for i in transmittance ])
    
    #흡광도_1 : -log10(I(투과방사선)/I0(입사방사선))  
    absorbance_1 = Series(map(lambda x : -math.log(x,10),transmittance))
    
    #흡광도_2 :  ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도) (농도는 1로 가정)
    # 흡광계수는 3번째 논문에서 찾은 적외선 종류중 NIR-1 의 뇌피질, 두개골, 피부의 감쇠계수의 합을 적용시켰습니다.
    absorbance_2 = Series(1/(((((s_rho)/10)**2)*2) * (n * 2.01)))
    
    # 흡광도 index 설정
    absorbance_1.index = set_index.map(lambda x : 'A1_' + x)
    absorbance_2.index = ['A2_rho']
    
    # 두 Series의 병합
    out_s = Series()
    out_s = out_s.append(absorbance_2).append(absorbance_1)
    # 튜닝된 설명변수의 Series반환
    return(out_s)



# train, test 흡광도 튜닝 => scaling까지 모두 튜닝완료단계, 여기서는 다른 스켈링모델 적용
tunning_train = train.apply(tuning_var2, axis = 1)
tunning_train=pd.merge(tunning_train,train.iloc[:,-4:],left_index=True, right_index=True)
tunning_test = test.apply(tuning_var2, axis = 1)
tunning_test=pd.merge(tunning_test,test.iloc[:,-4:],left_index=True, right_index=True)

m_sacled2 = StandardScaler()
m_sacled2.fit(tunning_train.iloc[:,:-4])
tunning_train.iloc[:,:]=np.append(m_sacled2.transform(tunning_train.iloc[:,:-4]),tunning_train.iloc[:,-4:],axis=1)

m_sacled2.fit(tunning_test.iloc[:,:-4])
tunning_test.iloc[:,:]=np.append(m_sacled2.transform(tunning_test.iloc[:,:-4]),tunning_test.iloc[:,-4:],axis=1)


# 4개 모델에서 각각의 X,Y 만들고 나누기
X1 = tunning_train.drop('hhb',axis=1)
Y1 = DataFrame(tunning_train.iloc[:,-4])
X2 = tunning_train.drop('hbo2',axis=1)
Y2 = DataFrame(tunning_train.iloc[:,-3])
X3 = tunning_train.drop('ca',axis=1)
Y3 = DataFrame(tunning_train.iloc[:,-2])
X4 = tunning_train.drop('na',axis=1)
Y4 = DataFrame(tunning_train.iloc[:,-1])

train_x1, test_x1, train_y1, test_y1 = train_test_split(X1,
                                                    Y1,
                                                    random_state = 0)
train_x2, test_x2, train_y2, test_y2 = train_test_split(X2,
                                                    Y2,
                                                    random_state = 0)
train_x3, test_x3, train_y3, test_y3 = train_test_split(X3,
                                                    Y3,
                                                    random_state = 0)
train_x4, test_x4, train_y4, test_y4 = train_test_split(X4,
                                                    Y4,
                                                    random_state = 0)


1) 1번 모델링 및 평가 
# 모델의 설정
model = Sequential() 
model.add(Dense(18, input_dim=39, activation='relu')) 
model.add(Dense(8, activation='relu'))
model.add(Dense(1))
 
# 모델 컴파일  
model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['MAE']) 
# 모델 실행 
model.fit(train_x1, train_y1, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x1,train_y1)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x1,test_y1)[1])) # 0.17

# 모델 저장 
model.save('model_ann_bio_611Y1_h5')   # h5 확장자로 저장

model611Y1=load_model('model_ann_bio_611Y1_h5')


2) 2번 모델링 및 평가
# 모델 실행 
model.fit(train_x2, train_y2, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x2,train_y2)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x2,test_y2)[1])) # 0.29

# 모델 저장 
model.save('model_ann_bio_611Y2_h5')   # h5 확장자로 저장
model611Y2=load_model('model_ann_bio_611Y2_h5')


3) 3번 모델링 및 평가
# 모델 실행 
model.fit(train_x3, train_y3, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x3,train_y3)[1])) # 0.36
print("\n MAE: %.4f" % (model.evaluate(test_x3,test_y3)[1]))

# 모델 저장 
model.save('model_ann_bio_611Y3_h5')   # h5 확장자로 저장
model611Y3=load_model('model_ann_bio_611Y3_h5')

4) 4번 모델링 및 평가
# 모델 실행 
model.fit(train_x4, train_y4, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x4,train_y4)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x4,test_y4)[1])) # 0.59

# 모델 저장 
model.save('model_ann_bio_611Y4_h5')   # h5 확장자로 저장
model611Y4=load_model('model_ann_bio_611Y4_h5')


# 각 4개 모델에 test.csv데이터(virtual y값 포함된) 적용해 최종 y값도출하기
TX1=tunning_test.drop('hhb',axis=1)
TX2=tunning_test.drop('hbo2',axis=1)
TX3=tunning_test.drop('ca',axis=1)
TX4=tunning_test.drop('na',axis=1)

Y1=model611Y1.predict(TX1)
Y2=model611Y2.predict(TX2)
Y3=model611Y3.predict(TX3)
Y4=model611Y4.predict(TX4)

a=np.append(Y1,Y2,axis=1)
b=np.append(Y3,Y4,axis=1)
c=np.append(a,b,axis=1)
d=m_sacled.inverse_transform(c)   # 역스케일링 적용해보았습니다

test2=pd.read_csv('sample_submission.csv',index_col='id')

test2.iloc[:,:]=d
test2.to_csv("test611_3.csv") 

결과 : 2나옴 
