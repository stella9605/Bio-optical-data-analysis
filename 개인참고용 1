# 찬희 하나씩 넣기

run profile_project

train = pd.read_csv('train.csv', index_col=0)
test = pd.read_csv('test.csv', index_col=0)

train.head()

train.isnull().sum()[train.isnull().sum().values > 0]

# 결측치 보완
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
test_dst.head(1)

train_dst = train_dst.interpolate(methods='quadratic', axis=1)
test_dst = test_dst.interpolate(methods='quadratic', axis=1)

# 스팩트럼 데이터에서 보간이 되지 않은 값은 0으로 일괄 처리한다.
train_dst.fillna(0, inplace=True) 
test_dst.fillna(0, inplace=True)

test_dst.head(1)

train.update(train_dst) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_dst)

X = train.iloc[:, :-4]
Y = train.iloc[:,-4:]

Y_1 = Y.iloc[:,0:1]
Y_2 = Y.iloc[:,1:2]
Y_3 = Y.iloc[:,2:3]
Y_4 = Y.iloc[:,3:4]

# train, test set
#### hbb
train_x, test_x, train_y, test_y = train_test_split(X,
                                                    Y_1,
                                                    random_state = 0)

#### hbo2
train_x, test_x, train_y, test_y = train_test_split(X,
                                                    Y_2,
                                                    random_state = 0)

#### ca
train_x, test_x, train_y, test_y = train_test_split(X,
                                                    Y_3,
                                                    random_state = 0)

#### na
train_x, test_x, train_y, test_y = train_test_split(X,
                                                    Y_4,
                                                    random_state = 0)

# train 변수 튜닝
tunning_train_x = train_x.apply(tuning_var, axis = 1)
tunning_test_x = test_x.apply(tuning_var, axis = 1)

# 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x)

x_scaled = m_sacled.transform(tunning_train_x)
test_x_scaled = m_sacled.transform(tunning_test_x)

# 모델 생성 함수 사용해서 모델생성
model_hhb = model_x(x_scaled, train_y, 50)     #  model_x사용법 : model_x(설명변수, 종속변수, epochs)입니다.
model_hbo2 = model_x(x_scaled, train_y, 50)
model_ca = model_x(x_scaled, train_y, 50)
model_na = model_x(x_scaled, train_y, 50)

# 모델 test
#### hhb
print("\n MAE: %.4f" % (model_hhb.evaluate(x_scaled,train_y)[1]))           # 0.79
print("\n MAE: %.4f" % (model_hhb.evaluate(test_x_scaled,test_y)[1]))       # 1.01

#### hbo2
print("\n MAE: %.4f" % (model_hbo2.evaluate(x_scaled,train_y)[1]))          # 0.54
print("\n MAE: %.4f" % (model_hbo2.evaluate(test_x_scaled,test_y)[1]))      # 0.67

#### ca
print("\n MAE: %.4f" % (model_ca.evaluate(x_scaled,train_y)[1]))            # 1.76
print("\n MAE: %.4f" % (model_ca.evaluate(test_x_scaled,test_y)[1]))        # 2.15

#### na
print("\n MAE: %.4f" % (model_na.evaluate(x_scaled,train_y)[1]))            # 1.07
print("\n MAE: %.4f" % (model_na.evaluate(test_x_scaled,test_y)[1]))        # 1.32



from keras.models import load_model
model_hhb.save('model_hhb_ann_bio_h5')   # h5 확장자로 저장 (hhb)
model_hbo2.save('model_hbo2_ann_bio_h5')   # hbo2
model_ca.save('model_ca_ann_bio_h5')   # ca
model_na.save('model_na_ann_bio_h5')   # na

dir(model)
model2_hhb=load_model('model_hhb_ann_bio_h5')
model2_hbo2=load_model('model_hbo2_ann_bio_h5')
model2_ca=load_model('model_ca_ann_bio_h5')  
model2_na=load_model('model_na_ann_bio_h5') 

## sample_submission.csv load
test1=pd.read_csv('sample_submission.csv',index_col='id')
test1=test1.astype('float')

# 진짜 테스트 변수 가공
tunning_realtest_x = test.apply(tuning_var, axis = 1)
realtest_x_scaled = m_sacled.transform(tunning_realtest_x)
realtest_x_scaled[-1]
test1.columns = ['hhb', 'hbo2', 'ca', 'na']
test1.hhb=model2_hhb.predict(realtest_x_scaled)
test1.hbo2=model2_hbo2.predict(realtest_x_scaled)
test1.ca=model2_ca.predict(realtest_x_scaled)
test1.na=model2_na.predict(realtest_x_scaled)
test1.to_csv("test1.csv")
