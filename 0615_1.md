##### 수정안) 흡광도2 없애고 해보기
 - 이유 : 두 개의 서로 다른 흡광도를 모두 학습시키기 보단 한개로서 적용하는 것
 - 감쇠계수를 적용해서 새로운 흡광도컬럼으로 추가했던 A2_rho 컬럼을 제외하고 학습시키기
 - 전체적인 모델링은 이전과 동일하게 4개의 모델로 돌렸으며 겹치는 코드는 일부생략함

#### * 결론
- MAE 0.4정도 줄어들어 의미있는 제거라고 생각됨
- 감쇠계수에 대한 정보가 없어서 이 정보를 추가해야 함

```python
tunning_train_edit1=tunning_train.iloc[:,1:]
tunning_test_edit1=tunning_test.iloc[:,1:] 

X1 = tunning_train_edit1.drop('hhb',axis=1)
Y1 = DataFrame(tunning_train_edit1.iloc[:,-4])
X2 = tunning_train_edit1.drop('hbo2',axis=1)
Y2 = DataFrame(tunning_train_edit1.iloc[:,-3])
X3 = tunning_train_edit1.drop('ca',axis=1)
Y3 = DataFrame(tunning_train_edit1.iloc[:,-2])
X4 = tunning_train_edit1.drop('na',axis=1)
Y4 = DataFrame(tunning_train_edit1.iloc[:,-1])

train_x1_edit1, test_x1_edit1, train_y1_edit1, test_y1_edit1 = train_test_split(X1,
                                                    Y1,
                                                    random_state = 0)
train_x2_edit1, test_x2_edit1, train_y2_edit1, test_y2_edit1 = train_test_split(X2,
                                                    Y2,
                                                    random_state = 0)
train_x3_edit1, test_x3_edit1, train_y3_edit1, test_y3_edit1 = train_test_split(X3,
                                                    Y3,
                                                    random_state = 0)
train_x4_edit1, test_x4_edit1, train_y4_edit1, test_y4_edit1 = train_test_split(X4,
                                                    Y4,
                                                    random_state = 0)


1)  
# 모델의 설정
model = Sequential() 
model.add(Dense(18, input_dim=38, activation='relu')) 
model.add(Dense(8, activation='relu'))
model.add(Dense(1))
 
# 모델 컴파일  
model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['MAE']) 
# 모델 실행 
model.fit(train_x1_edit1, train_y1_edit1, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x1_edit1,train_y1_edit1)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x1_edit1,test_y1_edit1)[1])) # 0.54

# 모델 저장 
model.save('model_ann_bio_611Y1_edit1_h5')   # h5 확장자로 저장

model611Y1=load_model('model_ann_bio_611Y1_edit1_h5')

2)
# 모델 실행 
model.fit(train_x2_edit1, train_y2_edit1, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x2_edit1,train_y2_edit1)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x2_edit1,test_y2_edit1)[1])) # 0.43

# 모델 저장 
model.save('model_ann_bio_611Y2_edit1_h5')   # h5 확장자로 저장
model611Y2=load_model('model_ann_bio_611Y2_edit1_h5')

3)
# 모델 실행 
model.fit(train_x3_edit1, train_y3_edit1, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x3_edit1,train_y3_edit1)[1])) # 0.43
print("\n MAE: %.4f" % (model.evaluate(test_x3_edit1,test_y3_edit1)[1]))

# 모델 저장 
model.save('model_ann_bio_611Y3_edit1_h5')   # h5 확장자로 저장
model611Y3=load_model('model_ann_bio_611Y3_edit1_h5')

4)
# 모델 실행 
model.fit(train_x4_edit1, train_y4_edit1, epochs=200, batch_size=10) 

print("\n MAE: %.4f" % (model.evaluate(train_x4_edit1,train_y4_edit1)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x4_edit1,test_y4_edit1)[1])) # 0.62

# 모델 저장 
model.save('model_ann_bio_611Y4_edit1_h5')   # h5 확장자로 저장

model611Y4=load_model('model_ann_bio_611Y4_edit1_h5')



# realtest에 적용
TX1=tunning_test_edit1.drop('hhb',axis=1)
TX2=tunning_test_edit1.drop('hbo2',axis=1)
TX3=tunning_test_edit1.drop('ca',axis=1)
TX4=tunning_test_edit1.drop('na',axis=1)

Y1=model611Y1.predict(TX1)
Y2=model611Y2.predict(TX2)
Y3=model611Y3.predict(TX3)
Y4=model611Y4.predict(TX4)

a=np.append(Y1,Y2,axis=1)
b=np.append(Y3,Y4,axis=1)
c=np.append(a,b,axis=1)
d=m_sacled.inverse_transform(c)

test2=pd.read_csv('sample_submission.csv',index_col='id')

test2.iloc[:,:]=d
test2.to_csv("test612.csv")
