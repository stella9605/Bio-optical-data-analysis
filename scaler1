# 토론에 있던 보간방법을 토대로 넣고 여러가지 스케일링을 넣어 테스트로 돌려봄
# minmax scaler, standardscaler, roburst scaler, minmax + standard, standard + minmax
run profile1

# 보간
train = pd.read_csv('train.csv', index_col=0)
test = pd.read_csv('test.csv', index_col=0)

train.head()

train.isnull().sum()[train.isnull().sum().values > 0]

# 결측치 보완
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
test_dst.head(1)

train_dst = train_dst.interpolate(methods='linear', axis=1)
test_dst = test_dst.interpolate(methods='linear', axis=1)
# 스팩트럼 데이터에서 보간이 되지 않은 값은 0으로 일괄 처리한다.
train_dst.fillna(0, inplace=True) 
test_dst.fillna(0, inplace=True)
test_dst.head(1)

train.update(train_dst) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_dst)

train = train.astype('float')
test = test.astype('float')

train.iloc[:,0:-4]

train_x, test_x, train_y, test_y = train_test_split(train.iloc[:,0:71],
                                                    train.iloc[:,-4:],
                                                    random_state=0)

# minmaxscaler
m_mms = MinMaxScaler()
m_mms.fit(train_x) # 각 설명변수의 최대, 최소 확인만
train_x_scaled = m_mms.transform(train_x) # 최대, 최소에 맞게 데이터 변환
test_x_scaled = m_mms.transform(test_x)

# standard scaler
m_scale = StandardScaler()
m_scale.fit(train_x)
train_x_sc = m_scale.transform(train_x)
test_x_sc = m_scale.transform(test_x)

m_svm = SVC()
m_svm.fit(train_x_scaled, train_y)
m_svm.score(test_x_scaled, test_y)  # 96.5

# robustScaler
from sklearn.preprocessing import RobustScaler
m_rsc = RobustScaler()
m_rsc.fit(train_x)
x_train_robust_scale = m_rsc.transform(train_x)
x_test_robust_scale = m_rsc.transform(test_x)

# minmax + standard scaler
m_scale = StandardScaler()
m_scale.fit(train_x_scaled)
train_x_sc = m_scale.transform(train_x_scaled)
test_x_sc = m_scale.transform(test_x_scaled)

# standard + minmax scaler
# minmaxscaler
m_mms = MinMaxScaler()
m_mms.fit(train_x_sc) # 각 설명변수의 최대, 최소 확인만
train_x_scaled = m_mms.transform(train_x_sc) # 최대, 최소에 맞게 데이터 변환
test_x_scaled = m_mms.transform(test_x_sc)


# 모델의 설정
model = Sequential() 
model.add(Dense(71, input_dim=71, activation='relu')) 
model.add(Dense(35, activation='relu')) 
model.add(Dense(17, activation='relu')) 
model.add(Dense(4, activation='softmax'))
 
# 모델 컴파일  
model.compile(loss='mean_squared_error', # loss='categorical_crossentropy'
              optimizer='adam',
              metrics=['accuracy']) 

# 모델 실행 
model.fit(train_x, train_y, epochs=500, batch_size=10)  # 60.56
model.fit(train_x_scaled, train_y, epochs=500, batch_size=10) # minmaxscaler : 62.08, 38.04
model.fit(train_x_sc, train_y, epochs=500, batch_size=10) # standard scaler 61.08, 38.04
model.fit(train_x_sc, train_y, epochs=500, batch_size=10) # minmax + standard 60.72
model.fit(x_train_robust_scale, train_y, epochs=500, batch_size=10) # robust scaler 0.38 
model.fit(train_x_scaled, train_y, epochs=500, batch_size=10) # standard + minmax 61.92
# => 결과
# Epoch 100/100
# 7500/7500 [==============================] - 1s 87us/step - 
# loss: 44.0200 - accuracy: 0.5888

 
# 결과 출력  
print("\n Accuracy: %.4f" % (model.evaluate(test_x,test_y)[1]))
print("\n Accuracy: %.4f" % (model.evaluate(test_x_scaled,test_y)[1]))
print("\n Accuracy: %.4f" % (model.evaluate(test_x_sc,test_y)[1]))
print("\n Accuracy: %.4f" % (model.evaluate(x_test_robust_scale,test_y)[1]))
