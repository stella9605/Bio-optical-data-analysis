# 목표값이 Y값의 0을 앞값과 뒷값의 평균으로 넣어보았음 (넣은 값이 맞는지는 확실치 않지만 0.3 오르긴 하였음)
그리고 4가지 스케일러를 사용
run profile1
import math


def tuning_var(s):
    s_rho = s[0]          # _rho
    s_src = s[1:36]       # _src
    s_dst = s[36:]        # _dst    

    # index 표준화
    set_index = s_src.index.str.split('_').str[0]
    s_src.index = set_index
    s_dst.index = set_index

    # 계산식 (흡광도 계산식)
    # A(흡광도) = -log10(I(투과방사선)/I0(입사방사선))  
    #           = ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도)
    
    s_ds_st = (s_dst / s_src)
    
    # 계산 완료후 inf,nan 0으로 치환
    s_ds_st = [i if i != np.inf else 0.0 for i in s_ds_st ]
    s_ds_st = Series(s_ds_st).fillna(value = 0)
    
    # math.log 계산을 위해 0을 1로 치환후 계산(흡광계수는 1로 가정한다.)
    s_ds_st = [1 if i == 0 else i for i in s_ds_st ]
    
    # 변수 튜닝 반환
    out_s = Series(map(lambda x : -math.log(x,10)/(((s_rho)/10)**2), s_ds_st))
    out_s.index= set_index
    return(out_s)

train = pd.read_csv('train.csv', index_col=0)
test = pd.read_csv('test.csv', index_col=0)

train2 = train.iloc[:,-4:]

train2[train2==0] = NA
train2 = (train2.fillna(method='ffill') + train2.fillna(method='bfill'))/2

train.iloc[:,-4:] = train2

# 결측치 보완
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
test_dst.head(1)

train_dst = train_dst.interpolate(methods='linear', axis=1)
test_dst = test_dst.interpolate(methods='linear', axis=1)
# 스팩트럼 데이터에서 보간이 되지 않은 값은 0으로 일괄 처리한다.
train_dst.fillna(0, inplace=True) 
test_dst.fillna(0, inplace=True)
test_dst.head(1)

train.update(train_dst) # 보간한 데이터를 기존 데이터프레임에 업데이트 한다.
test.update(test_dst)

X = train.iloc[:, :-4]
Y = train.iloc[:,-4:]

train_x, test_x, train_y, test_y = train_test_split(X,
                                                    Y,
                                                    random_state = 0)

# ---------------------------------------
# standard 스케일링
# train 변수 튜닝
tunning_train_x = train_x.apply(tuning_var, axis = 1)

# 튜닝 변수 스케일링
m_sacled = StandardScaler()
m_sacled.fit(tunning_train_x)
x_scaled = m_sacled.transform(tunning_train_x)

# test_x 변수 튜닝
tunning_test_x = test_x.apply(tuning_var, axis = 1)
# test_x 튜닝변수 스케일링
test_x_scaled = m_sacled.transform(tunning_test_x)

# ------------------------------------------
# minmax 스케일링
# train 변수 튜닝
tunning_train_x = train_x.apply(tuning_var, axis = 1)
# test_x 변수 튜닝
tunning_test_x = test_x.apply(tuning_var, axis = 1)

m_mms = MinMaxScaler()
m_mms.fit(tunning_train_x) # 각 설명변수의 최대, 최소 확인만
train_x_scaled = m_mms.transform(tunning_train_x) # 최대, 최소에 맞게 데이터 변환
test_x_scaled = m_mms.transform(tunning_test_x)

# -------------------------------------------------------
# robustScaler 스케일러
# train 변수 튜닝
tunning_train_x = train_x.apply(tuning_var, axis = 1)
# test_x 변수 튜닝
tunning_test_x = test_x.apply(tuning_var, axis = 1)

from sklearn.preprocessing import RobustScaler
m_rsc = RobustScaler()
m_rsc.fit(tunning_train_x)
x_train_robust_scale = m_rsc.transform(tunning_train_x)
x_test_robust_scale = m_rsc.transform(tunning_test_x)

# ------------------------------------------------------
# MaxAbsScaler 스케일러
# train 변수 튜닝
tunning_train_x = train_x.apply(tuning_var, axis = 1)
# test_x 변수 튜닝
tunning_test_x = test_x.apply(tuning_var, axis = 1)

from sklearn.preprocessing import MaxAbsScaler
maxAbsScaler = MaxAbsScaler()
maxAbsScaler.fit(tunning_train_x)
train_data_maxAbsScaled = maxAbsScaler.transform(tunning_train_x)
test_data_maxAbsScaled = maxAbsScaler.transform(tunning_test_x)


# 모델의 설정
model = Sequential() 
model.add(Dense(35, input_dim=35, activation='relu')) 
model.add(Dense(17, activation='relu')) 
model.add(Dense(4, activation='relu'))
 
# 모델 컴파일  
model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['MAE'])  # MAE로 변경
 
# 모델 실행 
model.fit(x_scaled, train_y, epochs=200, batch_size=10)  # standard 스케일링
model.fit(train_x_scaled, train_y, epochs=200, batch_size=10) # minmax 스케일링
model.fit(x_train_robust_scale, train_y, epochs=200, batch_size=10) # robust 스케일링
model.fit(train_data_maxAbsScaled, train_y, epochs=200, batch_size=10) #maxabs



print("\n Accuracy: %.4f" % (model.evaluate(x_scaled,train_y)[1])) # standard 스케일링 accuracy =  , MAE = 1.3143
print("\n Accuracy: %.4f" % (model.evaluate(test_x_scaled,test_y)[1])) # standard 스케일링 accuracy =  , MAE = 1.4263

print("\n Accuracy: %.4f" % (model.evaluate(train_x_scaled,train_y)[1])) # minmax 스케일링 accuracy =  , MAE = 1.3765
print("\n Accuracy: %.4f" % (model.evaluate(test_x_scaled,test_y)[1])) # minmax 스케일링 accuracy =  , MAE = 1.4621

print("\n Accuracy: %.4f" % (model.evaluate(x_train_robust_scale,train_y)[1])) # robust accuracy = , MAE = 1.3044          
print("\n Accuracy: %.4f" % (model.evaluate(x_test_robust_scale,test_y)[1])) # robust accuracy = , MAE = 1.4546            

print("\n Accuracy: %.4f" % (model.evaluate(train_data_maxAbsScaled,train_y)[1])) # maxabs accuracy = , MAE = 1.5112
print("\n Accuracy: %.4f" % (model.evaluate(test_data_maxAbsScaled,test_y)[1])) # maxabs accuracy = , MAE = 1.5785
