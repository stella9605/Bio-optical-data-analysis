import numpy as np
import pandas as pd

import random

import math

from numpy import nan as NA
from pandas import Series
from pandas import DataFrame

import cx_Oracle

import os

from datetime import datetime
from datetime import timedelta

def f_sql(sql_txt, 
          ip = '192.168.0.94',
          port = '1522', 
          oracle_id = 'scott', 
          passwd = 'oracle',
          sid='orcl1'):
    con1 = cx_Oracle.connect("%s/%s@%s:%s/%s" % (oracle_id,passwd,ip,port,sid))
    ex_table = pd.read_sql(sql_txt,con = con1)
    return ex_table

import re

# 데이터 셋
from sklearn.datasets import load_iris as iris
from sklearn.datasets import load_breast_cancer as cancer

#분석
from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsClassifier as knn
from sklearn.neighbors import KNeighborsRegressor as knn_r

from sklearn.tree import DecisionTreeClassifier as dt
from sklearn.tree import DecisionTreeRegressor as dt_r

from sklearn.ensemble import RandomForestClassifier as rf
from sklearn.ensemble import RandomForestRegressor as rf_r

from sklearn.preprocessing import PolynomialFeatures

# 1) minmax scaler
# - 각 설명변수마다 최소값에 0, 최대값에 1을 부여하여 재조절하는 방식
from sklearn.preprocessing import MinMaxScaler

# 2) standard scaler
# - 각 설명변수마다 표준화 시키는 방식
# - 표준화 : (x - xbar) / s  (xbar는 표본평균, s는 표본표준편차)
from sklearn.preprocessing import StandardScaler

from sklearn.svm import SVC

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# CV
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

# image 불러오
import imageio

import mglearn

# feature selection
from sklearn.feature_selection import SelectFromModel
from sklearn.feature_selection import SelectPercentile
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier

# 그리드 서치
from sklearn.model_selection import GridSearchCV

# 회귀모델
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso

# 딥러닝
import tensorflow as tf
import keras

from keras.models import Sequential   # 레이어 구조 구성
from keras.layers import Dense        # 레이어 안의 노드(뉴런)
from keras.utils import np_utils
from sklearn.preprocessing import LabelEncoder




######################################################### 함수

# 각 조직에 관환 감쇠계수, 감쇠길이
attenuation_coefficient = pd.DataFrame({'NIR-1' : [10,48,25], 
                                        'NIR-2' : [7.4,45,23],
                                        'SWIR' : [6.5,44,21],
                                        'SWIR-2' : [9,49,24.5]})

attenuation_coefficient.index = ['Brain_cortex','Cranial_bone','Skin']  # 인덱스 설정
 
n = attenuation_coefficient.mean(axis = 1).sum()  # 가각의 조직에 관한 적외선들의 감쇠 계수 들의 평균의 합

attenuation_length= pd.DataFrame({'NIR-1' : [1.0,0.2,0.4], 
                                  'NIR-2' : [1.35,0.22,0.44],
                                  'SWIR' : [1.54,0.23,0.47],
                                  'SWIR-2' : [1.11,0.2,0.41]})

attenuation_length.index = ['Brain_cortex','Cranial_bone','Skin']  # 인덱스 설정

n_l = attenuation_length.mean(axis = 1).sum()  # 가각의 조직에 관한 적외선들의 감쇠 길이 들의 평균의 합

##################### 설명변수 튜닝함수
def tuning_var(s):
    s_rho = s[0]          # _rho
    s_src = s[1:36]       # _src
    s_dst = s[36:]        # _dst    

    # index 표준화
    set_index = s_src.index.str.split('_').str[0]
    s_src.index = set_index
    s_dst.index = set_index

    # 계산식 (lambert beer 법칙)
    # A(흡광도) = -log10(I(투과방사선)/I0(입사방사선))  
    #           = ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도)
    
    # 투광도
    transmittance = (s_dst / s_src)
    
    # 계산 완료후 inf,nan 0으로 치환
    transmittance = [i if i != np.inf else 0.0 for i in transmittance ]
    transmittance = Series(transmittance).fillna(value = 0)

    # math.log 계산을 위해 0을 1로 치환후 계산(흡광계수는 1로 가정한다.)
    transmittance = Series([1 if i == 0 else i for i in transmittance ])
    
    #흡광도_1 : -log10(I(투과방사선)/I0(입사방사선))  
    absorbance_1 = Series(map(lambda x : -math.log(x,10),transmittance))
    
    #흡광도_2 :  ε(흡광계수) ⋅ b(투과 경로 길이(cm)) ⋅ c(농도) (농도는 1로 가정) 
    # 흡광계수는 감쇠계수 * 감쇠길이(cm)로 사용
    absorbance_2 = Series(((((s_rho)/10) * (n * (n_l * 0.1)))))
    
    # 흡광도 index 설정
    absorbance_1.index = set_index.map(lambda x : 'A1_' + x)
    absorbance_2.index = ['A2_rho']
    
    # 두 Series의 병합
    out_s = Series()
    out_s = out_s.append(absorbance_2).append(absorbance_1)
    # 튜닝된 설명변수의 Series반환
    return(out_s)

# 모델 생성 함수
def model_x(train_x, train_y, number):
   
    # 모델의 설정
    model = Sequential() 
    model.add(Dense(18, input_dim=36, activation='relu')) 
    model.add(Dense(8, activation='relu'))
    model.add(Dense(4, activation='relu'))
    model.add(Dense(1, activation='relu'))
    
    # 모델 컴파일
    model.compile(loss='mean_squared_error',
                  optimizer='adam',
                  metrics=['MAE'])
 
    # 모델 실행 
    model.fit(train_x, train_y, epochs=number, batch_size=10) 
    return(model)
