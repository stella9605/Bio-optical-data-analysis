** 공지
- 앞으로 이전모델하고 비교하려면 모델 저장도 해야할 것 같습니다!
- 만든 모델에 대해 평가수치(mae) 값을 명시해서 올리면 더 보기 편할 것 같네요
-------------------
-------------------

오늘 만든 3가지 모델을 만들어봤습니다
#### model1) relu, mae 로 변경
- 먼저 저희 공모전 평가지표가 accurancy가 아닌 mea(절대오차지수?)여서 이걸로 바꿨어요 그리고 이때 사용하는 loss함수도 mean_absolute_error로 설정했습니다.
- 저희 데이터의 종속변수가 범주형이 아닌 연속형이기 떄문에 마지막 층에서 사용하는 activation fuction이 시그모이드, 소프트맥스가 되면 안되기 때문에 값 그대로 값을 전달할 수 있는 relu로 사용했어요
- 그리고 adsp준비하면서 보니까 일단은 히든층을 1개로 설정해서 점점 최적화시켜나가는게 좋다고 해서 하나로 줄였습니다. 나중에 마무리할 때 층 개수랑 노드 수 최적화하면 될 것 같아요
어떻게 생각하시나요?? 의견있으시면 얘기해주세요 
- 수정한 코드부분만 올립니다
```python
#### model1
# 모델의 설정
model = Sequential()
model.add(Dense(17, input_dim=35, activation='relu')) 
model.add(Dense(4, activation='relu'))
 
# 모델 컴파일  
model.compile(loss='mean_absolute_error',
              optimizer='adam',
              metrics=['mae']) 
 
# 모델 실행 
model.fit(x_scaled, train_y, epochs=200, batch_size=10) 


# test_x 변수 튜닝
tunning_test_x = test_x.apply(tuning_var, axis = 1)


# test_x 튜닝변수 스케일링
test_x_scaled = m_sacled.transform(tunning_test_x)

print("\n MAE: %.4f" % (model.evaluate(x_scaled,train_y)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x_scaled,test_y)[1]))

from keras.models import load_model
model.save('model_ann_bio_h5')   # h5 확장자로 저장

dir(model)
model1=load_model('model_ann_bio_h5')
model.evaluate(test_x_scaled,test_y)[1]
=> 1.58   # 이거 올리실 때 꼭 적어주세요!!!
```
----------------------



#### model2) interpolate(methods='quadratic' 로 변경
- 전처리단계에서 사용한 interpolate함수는 결측치 값을 적절한 값으로 변경하는데 사용하는 함수입니다
원래 저희가 default값인 method='linear'를 설정했는데 찾아보시면 아시겠지만 좀 더 그래프가 smooth하게 그려지기 위해서는 quadratic과 같은 method를 써야하더라구요 
- 다른 기법들에 대해서도 알아보고 더 좋은 method를 선별할 필요가 있을 것 같습니다.
- 코드 맨 하단에 method에 대한 parameter값들 올려봤어요
```python
# 결측치 보완
train_dst = train_dst.interpolate(methods='quadratic', axis=1)
test_dst = test_dst.interpolate(methods='quadratic', axis=1)
...
...
model2=load_model('model_ann_bio1_h5') 
model2.evaluate(test_x_scaled,test_y)[1]  
=> 1.5913690328598022


#Parameters
----------
method : str, default 'linear'
    Interpolation technique to use. One of:

    * 'linear': Ignore the index and treat the values as equally
      spaced. This is the only method supported on MultiIndexes.
    * 'time': Works on daily and higher resolution data to interpolate
      given length of interval.
    * 'index', 'values': use the actual numerical values of the index.
    * 'pad': Fill in NaNs using existing values.
    * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',
      'barycentric', 'polynomial': Passed to
      `scipy.interpolate.interp1d`. These methods use the numerical
      values of the index.  Both 'polynomial' and 'spline' require that
      you also specify an `order` (int), e.g.
      ``df.interpolate(method='polynomial', order=5)``.
    * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima':
      Wrappers around the SciPy interpolation methods of similar
      names. See `Notes`.
    * 'from_derivatives': Refers to
      `scipy.interpolate.BPoly.from_derivatives` which
      replaces 'piecewise_polynomial' interpolation method in
      scipy 0.18.
axis : {0 or 'index', 1 or 'columns', None}, default None
    Axis to interpolate along.
limit : int, optional
    Maximum number of consecutive NaNs to fill. Must be greater than
    0.
inplace : bool, default False
    Update the data in place if possible.
limit_direction : {'forward', 'backward', 'both'}, default 'forward'
    If limit is specified, consecutive NaNs will be filled in this
    direction.
limit_area : {`None`, 'inside', 'outside'}, default None
    If limit is specified, consecutive NaNs will be filled with this
    restriction.

    * ``None``: No fill restriction.
    * 'inside': Only fill NaNs surrounded by valid values
      (interpolate).
    * 'outside': Only fill NaNs outside valid values (extrapolate).

    .. versionadded:: 0.23.0

downcast : optional, 'infer' or None, defaults to None
    Downcast dtypes if possible.
**kwargs
    Keyword arguments to pass on to the interpolating function.
```
---------------------
#### model3)  전처리 시 0값은 그대로, 결측치(값 없는거)만 보간함수 사용하기
- 이전까지의 코드 보시면 저희가 0인 값도 결측치(nan)값으로 바꾼 후 interpolate로 보간했는데 0인 값은 그 자체로 의미를 가지고 있지 않을까해서 이건 그냥 놔두고 바로 interpolate 써서 애초에 nan인 값만 보간해서 모델링해보았습니다.
```python               
# 결측치 보완
-----------------------------------삭제
train_dst = train.filter(regex='_dst$', axis=1).replace(0, np.NaN) # dst 데이터만 따로 뺀다.
test_dst = test.filter(regex='_dst$', axis=1).replace(0, np.NaN) # 보간을 하기위해 결측값을 삭제한다.
-----------------------------------삭제

train_dst = train_dst.interpolate(methods='quadratic', axis=1)
test_dst = test_dst.interpolate(methods='quadratic', axis=1)
# 스팩트럼 데이터에서 보간이 되지 않은 값은 0으로 일괄 처리한다.
train_dst.fillna(0, inplace=True) 
test_dst.fillna(0, inplace=True)
test_dst.head(1)
..
..

print("\n MAE: %.4f" % (model.evaluate(x_scaled,train_y)[1]))
print("\n MAE: %.4f" % (model.evaluate(test_x_scaled,test_y)[1]))

from keras.models import load_model
model.save('model_ann_bio_h5')   # h5 확장자로 저장

dir(model)
model3=load_model('model_ann_bio_h5')
model3.evaluate(test_x_scaled,test_y)[1]
=> 1.5321
```

결론 : relu, mae 로 변경
       전처리는 0인 값은 그대로 놔두는게 좋을 듯
       interpolate사용 시 method인자는 더 적용해봐야함
